{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"JonaKoenemann/machine_failure_classification\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"JonaKoenemann/machine_failure_classification\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository JonaKoenemann/machine_failure_classification initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository JonaKoenemann/machine_failure_classification initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set up dagshub for mlflow tracking\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='JonaKoenemann', repo_name='machine_failure_classification', mlflow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../data/predictive_maintenance.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Type']\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove('UDI')\n",
    "numerical_features.remove('Target')\n",
    "\n",
    "# Feature Engineering: Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', poly)\n",
    "        ]), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for features (X) und labels (y)\n",
    "X = df[numerical_features + categorical_features] # select Features \n",
    "y = df[\"Failure Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 23)\n",
      "(2000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Test preprocessor pipeline\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the MLflow experiment\n",
    "mlflow.set_experiment(\"logistic_regression_rs_feature\")\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Define the parameters for GridSearchCV\n",
    "param_distributions = {\n",
    "    'model__penalty': [None, 'l1', 'l2'],\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100], \n",
    "    'model__class_weight': [None, 'balanced'],\n",
    "    'model__solver': ['saga']\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# weighted f1 score as scoring metric\n",
    "scorer = make_scorer(f1_score, average = \"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/24 12:24:52 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/24 12:25:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 30 is smaller than n_iter=50. Running 30 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/06/24 12:29:48 WARNING mlflow.sklearn.utils: BaseSearchCV.score failed. The 'training_score' metric will not be recorded. Scoring error: pos_label=1 is not a valid label: It should be one of ['Heat Dissipation Failure' 'No Failure' 'Overstrain Failure'\n",
      " 'Power Failure' 'Random Failures' 'Tool Wear Failure']\n",
      "2024/06/24 12:29:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jkoenemann\\GitHub\\machine_failure_classification\\venv\\Lib\\site-packages\\mlflow\\types\\utils.py:394: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/06/24 12:30:16 INFO mlflow.sklearn.utils: Logging the 5 best runs, 25 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "weighted f1 score: 0.9695695721258611\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    print(\"Training Logistic Regression Model...\")\n",
    "    randomized_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_distributions,\n",
    "                                           n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1, scoring=scorer)\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_params = randomized_search.best_params_\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    best_model = randomized_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # evaluation\n",
    "    weighted_f1 = f1_score(y_true = y_test, y_pred= y_pred, average=\"weighted\")\n",
    "    print(\"\\nweighted f1 score:\", weighted_f1)\n",
    "    mlflow.log_metric('weighted_f1_score', weighted_f1)\n",
    "    \n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_names = [\n",
    " 'Heat Failure',\n",
    " 'No Failure',\n",
    " 'Overstrain Failure',\n",
    " 'Power Failure',\n",
    " 'Random Failure',\n",
    " 'Tool wear Failure'] # get names of errors in correct order for confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Normalized Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_normalized = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, cmap=\"Blues\", cbar=False, xticklabels=error_names, yticklabels=error_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
