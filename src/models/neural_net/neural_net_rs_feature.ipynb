{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install setuptools\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "!{sys.executable} -m pip install mlflow\n",
    "!{sys.executable} -m pip install dagshub\n",
    "!{sys.executable} -m pip install keras-tuner\n",
    "!{sys.executable} -m pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import dagshub\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dagshub for mlflow tracking\n",
    "dagshub.init(repo_owner='JonaKoenemann', repo_name='machine_failure_classification', mlflow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../../data/predictive_maintenance.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Type']\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove('UDI')\n",
    "numerical_features.remove('Target')\n",
    "\n",
    "# Feature Engineering: Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', poly)\n",
    "        ]), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for features (X) und labels (y)\n",
    "X = df[numerical_features + categorical_features] # select Features \n",
    "y = df[\"Failure Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test preprocessor pipeline\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model creation function\n",
    "def create_model(input_shape, optimizer='adam', init='glorot_uniform', layers=[64, 32], **kwargs):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))  # Input layer with input_shape parameter\n",
    "    for neurons in layers:\n",
    "        model.add(Dense(neurons, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters distribution\n",
    "param_dist = {\n",
    "    'model__batch_size': randint(16, 65),\n",
    "    'model__epochs': randint(10, 31),\n",
    "    'model__optimizer': ['SGD', 'Adam'],\n",
    "    'model__layers': [[64, 32], [64, 32, 16]]  # List of layer configurations to test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RandomizedSearchCV with F1 score as the metric\n",
    "n_iter_search = 10\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, n_iter=n_iter_search, cv=3, n_jobs=-1, scoring=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"neural_net_rs_feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    # Fit random search\n",
    "    random_search_result = random_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Log the best parameters and metrics\n",
    "    mlflow.log_params(random_search_result.best_params_)\n",
    "    mlflow.log_metric(\"best_score\", random_search_result.best_score_)\n",
    "    \n",
    "    # Train the best model on the test data\n",
    "    best_model = random_search_result.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_transformed)\n",
    "    test_accuracy = best_model.score(X_test_transformed, y_test)\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    \n",
    "    # Calculate and log the F1 score\n",
    "    test_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "    mlflow.log_metric(\"test_f1_score\", test_f1_score)\n",
    "    \n",
    "    print(f\"Best Parameters: {random_search_result.best_params_}\")\n",
    "    print(f\"Best CV F1 Score: {random_search_result.best_score_}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    print(f\"Test F1 Score: {test_f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_names = [\n",
    " 'Heat Failure',\n",
    " 'No Failure',\n",
    " 'Overstrain Failure',\n",
    " 'Power Failure',\n",
    " 'Random Failure',\n",
    " 'Tool wear Failure'] # get names of errors in correct order for confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_normalized = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, cmap=\"Blues\", cbar=False, xticklabels=error_names, yticklabels=error_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.model_.history\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
